died = rbinom(length(the_id), 1, covid_ifr),
death_date = ifelse(died, start_day + 14, NA)
)
covid_case_simulation_lockdown_late = run_case_simulation(the_r0 = NULL,  lockdown_date = 45, lockdown_effect = 0.65, initial_susceptible = initial_susceptible) %>%
mutate(
start_day = floor(incubation_start_date),
died = rbinom(length(the_id), 1, covid_ifr),
death_date = ifelse(died, start_day + 14, NA)
)
flu_case_simulation = run_case_simulation(the_r0 = 1.3) %>%
mutate(
start_day = floor(incubation_start_date),
died = rbinom(length(the_id), 1, flu_ifr),
death_date = ifelse(died, start_day + 14, NA)
)
covid_cases_by_day = dplyr::group_by(covid_case_simulation, start_day) %>%
dplyr::summarize(
obs = n_distinct(the_id),
died = sum(died)
) %>%
mutate(
cum_obs = cumsum(obs),
Virus = 'COVID-19',
with_lockdown = 'No'
)
covid_cases_by_day_lockdown = dplyr::group_by(covid_case_simulation_lockdown, start_day) %>%
dplyr::summarize(
obs = n_distinct(the_id),
died = sum(died)
) %>%
mutate(
cum_obs = cumsum(obs),
Virus = 'COVID-19 Early Lockdown',
with_lockdown = 'Yes'
)
covid_cases_by_day_lockdown_mid = dplyr::group_by(covid_case_simulation_mid_lockdown, start_day) %>%
dplyr::summarize(
obs = n_distinct(the_id),
died = sum(died)
) %>%
mutate(
cum_obs = cumsum(obs),
Virus = 'COVID-19 Mid Lockdown',
with_lockdown = 'Yes'
)
covid_cases_by_day_lockdown_late = dplyr::group_by(covid_case_simulation_lockdown_late, start_day) %>%
dplyr::summarize(
obs = n_distinct(the_id),
died = sum(died)
) %>%
mutate(
cum_obs = cumsum(obs),
Virus = 'COVID-19 Late Lockdown',
with_lockdown = 'Yes'
)
flu_cases_by_day = dplyr::group_by(flu_case_simulation, start_day) %>%
dplyr::summarize(
obs = n_distinct(the_id),
died = sum(died)
) %>%
mutate(
cum_obs = cumsum(obs),
Virus = 'Influenza',
with_lockdown = 'No'
)
stacked_stats = bind_rows(
covid_cases_by_day, flu_cases_by_day, covid_cases_by_day_lockdown_mid,
covid_cases_by_day_lockdown, covid_cases_by_day_lockdown_late)
group_by(stacked_stats, Virus, with_lockdown) %>%
summarize(
t_obs = sum(obs),
pct_infected = t_obs / initial_susceptible,
t_died = sum(died),
crude_mortality_rate = t_died / initial_susceptible,
infection_fatality_rate = t_died / t_obs,
time_period = as.numeric(max(start_day)-min(start_day))
)
ggplot(stacked_stats, aes(start_day, obs, fill = Virus)) +
geom_area(alpha = 0.3, position = 'identity')
# https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html
# https://covidtracking.com/api/
# https://covid.ourworldindata.org
library(R0)
library(plotly)
library(rnaturalearth)
library(rnaturalearthdata)
library(rgeos)
library(data.table)
library(countrycode)
library(viridis)
library(gganimate)
library(gifski)
library(tidyverse)
library(lmtest)
library(WDI)
library(plotly)
library(USAboundaries)
library(sf)
library(fuzzyjoin)
library(tigris)
library(scales)
library(ggthemes)
library(usmap)
library(cowplot)
library(RcppRoll)
library(sqldf)
library(albersusa)
library(RColorBrewer)
library(quantreg)
library(ggrepel)
# display.brewer.all(n=NULL, type="all", select=NULL, exact.n=TRUE,
#                    colorblindFriendly=FALSE)
# questions to answer:
# how have case / death rates changed recently?
# how have transmission rates changes over time?
# what do we know about mortality rates?
# how many cases are missing?
# what is the geographic distribution of cases, and how does proximity affect transmission?
setwd("~/Public_Policy/Projects/COVID-19")
r0_window_size = 7
est_r0_window = function(new_cases, catch = F) {
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7014672/
mGT <- generation.time("weibull", c(6.4, 2.3))
# new_cases = a$the_cases
if (!catch) {
r0_est = est.R0.EG(new_cases, mGT, begin=as.integer(1), end=as.integer(length(new_cases)))$R
return(r0_est)
} else {
r0_est = NA
tryCatch({
r0_est = est.R0.EG(new_cases, mGT, begin=as.integer(1), end=as.integer(length(new_cases)))$R
}, error = function(e){
return(r0_est)
})
}
}
### get state and US population data  ###
fred_sqlite = dbConnect(SQLite(), dbname= "data/fred_sqlite.sqlite")
state_economic_data = dbGetQuery(fred_sqlite, 'select * from state_economic_data') %>%
mutate(
date = as.Date(date, origin = '1970-01-01'),
title_clean = str_extract(title, '(.* in )|(.* for )') %>% str_replace('( in )|( for )', ''),
title_for_col = paste0("x_", str_replace_all(title_clean, '[ \\-%,]', '_'))
) %>%
arrange(state_name, title_clean, date) %>%
data.table() %>%
# accidentally inserted duplicate records for Alabama, dedup here (need to index this db later)
unique(by = c('state_name', 'title_clean', 'date'))
annual_population_by_state = filter(state_economic_data, title_clean == 'Resident Population') %>%
mutate(
year = year(date)
)
population_by_state = filter(annual_population_by_state, date == max(date))
us_population = sum(population_by_state$value)
## get shapefile data ##
us_counties_shp = us_counties()
us_states_shp = us_states()
us_map = USAboundaries::us_boundaries()
us_states_tigris = tigris::states()
us_counties_tigris = tigris::counties()
# remotes::install_git("https://git.sr.ht/~hrbrmstr/albersusa")
# https://github.com/hrbrmstr/albersusa
us_sf <- usa_sf("laea")
cty_sf <- counties_sf("aeqd")
state_geo_center = us_states_tigris@data %>%
mutate(
lat = as.numeric(INTPTLAT),
long = as.numeric(INTPTLON)
) %>%
rename(
state_abbr = STUSPS
)
### get lockdown dates ###
tryCatch({
lockdown_dates = read_csv('https://covid19-lockdown-tracker.netlify.com/lockdown_dates.csv') %>%
rename(location_name = Place, lockdown_start = `Start date`, lockdown_end = `End date`)
if (nrow(lockdown_dates) > 0) {
write.csv(lockdown_dates, 'data/lockdown_dates.csv', row.names = F)
}
}, error = function(e){
cat('error reading lockdown dates\n')
print(e)
}, finally = {
if (!'lockdown_dates' %in% ls()) {
lockdown_dates = read_csv('data/lockdown_dates.csv')
}
})
us_lockdown_dates = filter(lockdown_dates, Country == 'United States', Level == 'State') %>%
select(-Country, -Confirmed, -Level)
names(us_lockdown_dates) = names(us_lockdown_dates) %>% str_replace_all(' ', '_')
#### load and clean state covid data ####
us_covid_data = read_csv('https://covidtracking.com/api/us/daily.csv') %>%
mutate(
date = as.Date(as.character(date), format = '%Y%m%d'),
location = 'United States',
location_type = 'country',
data_source = 'covidtracking.com',
location_key = paste(location, location_type, data_source, sep = '|')
) %>%
arrange(date) %>%
rename(
total_cases = positive,
total_deaths = death,
total_tests = total
) %>%
mutate(
percent_positive_cases = total_cases / (total_cases + negative),
tests_with_results = negative + total_cases,
case_fatality_rate = total_deaths / total_cases
)
state_name_mappings = tibble(state_name = state.name, state_abbr = state.abb)
us_states_covid_data = read_csv('http://covidtracking.com/api/states/daily.csv') %>%
mutate(
date = as.Date(as.character(date), format = '%Y%m%d'),
location_type = 'US State',
data_source = 'covidtracking.com',
location_key = paste(state, location_type, data_source, sep = '|')
) %>%
arrange(location_key, date) %>%
rename(
total_cases = positive,
total_deaths = death,
total_tests = total,
location = state
) %>%
mutate(
percent_positive_cases = total_cases / (total_cases + negative),
tests_with_results = negative + total_cases,
case_fatality_rate = total_deaths / total_cases
)
all_covid_data_stacked = bind_rows(us_covid_data, us_states_covid_data) %>%
arrange(location_key, date) %>%
pivot_longer(cols = c('total_cases', 'total_deaths', 'total_tests',
'percent_positive_cases', 'case_fatality_rate', 'tests_with_results'),
names_to = c('measure'), values_to = 'value') %>%
data.table()
# compute first differences, pct changes, etc. by state
all_covid_data_diffs =
all_covid_data_stacked[, {
lag_value = lag(value, 1)
diff_value = value - lag_value
pct_change_value = diff_value / lag_value
cum_diff_value = value - lag_value
cum_diff_value[is.na(cum_diff_value)] = value[1]
lag_4_value = lag(value, 4)
lag_5_value = lag(value, 5)
lag_6_value = lag(value, 6)
cum_lag_4_diff_value = lag(cum_diff_value, 4)
cum_lag_5_diff_value = lag(cum_diff_value, 5)
cum_lag_6_diff_value = lag(cum_diff_value, 6)
value_avg_3 = c(rep(NA, 2), roll_mean(value, 3))
diff_value_avg_3 = c(rep(NA, 2), roll_mean(diff_value, 3))
list(
time = as.integer(date - min(date)),
date = date,
value = value,
lag_value = lag_value,
diff_value = diff_value,
pct_change_value = pct_change_value,
value_avg_3 = value_avg_3,
diff_value_avg_3 = diff_value_avg_3,
lag_4_value = lag_4_value,
lag_5_value = lag_5_value,
lag_6_value = lag_6_value,
cum_diff_value = cum_diff_value,
cum_lag_4_diff_value = cum_lag_4_diff_value,
cum_lag_5_diff_value = cum_lag_5_diff_value,
cum_lag_6_diff_value = cum_lag_6_diff_value,
first_value = date[date == min(date)],
last_value = date[date == max(date)],
value_past_100 = min(date[value >= 100])
)
}, by = list(location_key, location, location_type, data_source, measure)] %>%
pivot_wider(
id_cols = c('location_key', 'location', 'location_type','data_source', 'date', 'time'),
names_from = 'measure',
values_from = c('value', 'lag_value', 'diff_value',
'pct_change_value', 'lag_4_value', 'lag_5_value',
'lag_6_value', 'value_avg_3', 'diff_value_avg_3',
'cum_lag_4_diff_value', 'cum_lag_5_diff_value',
'cum_lag_6_diff_value', 'cum_diff_value')
) %>%
left_join(
state_name_mappings, by = c('location' = 'state_abbr')
) %>%
left_join(
select(population_by_state, state_name, state_pop = value)
) %>%
left_join(
tibble(location = 'United States', us_pop = us_population), by = 'location'
) %>%
mutate(
location_name = ifelse(is.na(state_name), location, state_name),
population = ifelse(is.na(state_pop), us_pop, state_pop) * 1000,
pop_100k = population/100000,
state_pop = NULL, us_pop = NULL
)
### get timing of when the 20th case occurred ###
case_20_dates = group_by(all_covid_data_diffs, location_key) %>%
summarize(
date_case_20 = min(date[value_total_cases >= 20]),
has_30_days = as.numeric(max(date[value_total_cases >= 20]) - min(date[value_total_cases >= 20]) >= 30)
)
all_covid_data_diffs_dt = data.table(all_covid_data_diffs)
### one more set of by-state computations, to get r0 and other stats ###
effective_r0_dat = all_covid_data_diffs_dt[, {
# ny = filter(all_covid_data_diffs_dt, location == 'NY')
# attach(ny)
cum_diff_value_total_cases[value_total_cases == 0] = NA
# what is the r0 of cases on a rolling 6 day basis? This uses the last six days, computes r0, and then pushes the computations
# forward six days to show the r0 of the cases themselves
new_cases_zoo = zoo(cum_diff_value_total_cases, 1:length(cum_diff_value_total_cases))
r0_rolling = rep(NA, length(new_cases_zoo)) %>% as.numeric()
tryCatch({
r0_rolling = c(rep(NA, r0_window_size-1), rollapply(new_cases_zoo %>% na.approx(new_cases_zoo, na.rm = F), r0_window_size, est_r0_window)) %>%
lead(r0_window_size) %>% as.numeric()
}, error = function(e){
print( e)
})
# Median is 5.1 days, mean is 6.4 days
# https://annals.org/aim/fullarticle/2762808/incubation-period-coronavirus-disease-2019-covid-19-from-publicly-reported
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7014672/
effective_r0 = cum_diff_value_total_cases / cum_lag_6_diff_value_total_cases
#
# # there are NAs because of the lags, there are infinite values because of missing data
effective_r0_nas = ifelse(is.infinite(effective_r0) | effective_r0 == 0, NA, effective_r0) %>% as.numeric()
#
# # interpolate the cases
effective_r0_interpolated = zoo(effective_r0_nas, 1:length(effective_r0_nas)) %>% na.approx(na.rm = F) %>% as.numeric()
#
# # there are data integrity issues. Limit max r0 to 20 and min to 0
effective_r0_interpolated = pmin(effective_r0_interpolated, 20)
effective_r0_interpolated = pmax(effective_r0_interpolated, 0)
# this needs to be pushed back to where the cases originated
effective_r0_interpolated_lead = lead(effective_r0_interpolated, 6)
# get rolling average positive tests for last seven days
percent_positive_new_tests = cum_diff_value_total_cases / cum_diff_value_tests_with_results
rolling3_tests_with_results = c(rep(NA, 2), roll_mean(cum_diff_value_tests_with_results, 3))
rolling7_tests_with_results = c(rep(NA, 6), roll_mean(cum_diff_value_tests_with_results, 7))
rolling3_new_cases = c(rep(NA, 2), roll_mean(cum_diff_value_total_cases, 3))
lag_percent_positive_new_tests = lag(percent_positive_new_tests, 1)
delta_percent_positive_new_tests = percent_positive_new_tests - lag_percent_positive_new_tests
rolling3_percent_positive_new_tests = c(rep(NA, 2), roll_mean(percent_positive_new_tests, 3))
rolling7_percent_positive_new_tests = c(rep(NA, 6), roll_mean(percent_positive_new_tests, 7))
delta_roll_3_7 = rolling3_percent_positive_new_tests - rolling7_percent_positive_new_tests
# there is some thinking that there is a severe lag in case reporting, use a weeklong lag
# the reason we use lead
r0_rolling_lead_7 = lead(r0_rolling, 7)
effective_r0_interpolated_lead_7 = lead(effective_r0_interpolated, 7)
list(
date = date,
effective_r0_interpolated = effective_r0_interpolated_lead,
effective_r0_interpolated_lead_7 = effective_r0_interpolated_lead_7,
r0_rolling = r0_rolling,
r0_rolling_lead_7 = r0_rolling_lead_7,
percent_positive_new_tests = percent_positive_new_tests,
lag_percent_positive_new_tests = lag_percent_positive_new_tests,
delta_percent_positive_new_tests = delta_percent_positive_new_tests,
rolling3_new_cases = rolling3_new_cases,
rolling3_tests_with_results = rolling3_tests_with_results,
rolling7_tests_with_results = rolling7_tests_with_results,
rolling3_percent_positive_new_tests = rolling3_percent_positive_new_tests,
rolling7_percent_positive_new_tests = rolling7_percent_positive_new_tests,
delta_roll_3_7_percent_positive_new_tests = delta_roll_3_7
)
}, by = list(location_key, location)]
# what is the r0 of cases on a rolling 6 day basis? This uses the last six days, computes r0, and then pushes the computations
# forward six days to show the r0 of the cases themselves
# final, clean dataset with all sorts of calculations complete #
all_covid_data_diffs_dates = left_join(all_covid_data_diffs, case_20_dates) %>%
left_join(effective_r0_dat) %>%
left_join(us_lockdown_dates) %>%
mutate(
days_since_lockdown_start = as.numeric(date - lockdown_start),
lockdown_period = ifelse(is.na(lockdown_start), 'No Lockdown', ifelse(days_since_lockdown_start < 0, 'Pre-Lockdown', 'Post-Lockdown')) %>%
factor() %>% relevel(ref = 'Pre-Lockdown'),
days_since_case_20 = as.numeric(date - date_case_20),
days_since_first_state_lockdown = as.numeric(date - min(lockdown_start, na.rm = T)),
post_first_lockdown = days_since_first_state_lockdown >= 0,
new_tests_per_100k = cum_diff_value_total_tests / pop_100k,
tests_per_100k = value_total_tests / pop_100k,
cases_per_100k = value_total_cases / pop_100k,
new_cases_per_100k = cum_diff_value_total_cases / pop_100k,
deaths_per_100k = value_total_deaths / pop_100k,
diff_value_avg_3_total_tests_per_100k = diff_value_avg_3_total_tests / pop_100k,
week_day = lubridate::wday(date),
weekend_ind = ifelse(week_day %in% c(7, 1), 'Weekend', "Week Day"),
cum_diff_value_total_cases_adj = pmax(cum_diff_value_total_cases, 0),
cum_diff_value_tests_with_results_adj = pmax(cum_diff_value_total_cases_adj, cum_diff_value_tests_with_results, 0),
cum_diff_value_tests_with_results_adj = ifelse(cum_diff_value_tests_with_results_adj == 0, NA, cum_diff_value_tests_with_results_adj)
) %>%
arrange(location_key, date) %>%
filter(
location %in% c(state.abb, 'United States')
)
write.csv(all_covid_data_diffs_dates, 'data/us_covid_data_by_state_with_calcs.csv', row.names = F)
r0_stats_by_date = group_by(all_covid_data_diffs_dates, date, lockdown_period) %>%
summarize(
obs = n(),
median_r0 = median(r0_rolling_lead_7, na.rm = T),
mean_r0 = mean(r0_rolling_lead_7, na.rm = T),
q25 = quantile(r0_rolling_lead_7, probs = 0.25, na.rm = T),
q75 = quantile(r0_rolling_lead_7, probs = 0.75, na.rm = T)
) %>%
filter(!is.na(median_r0)) %>%
mutate(
pct_of_states = obs/sum(obs)
)
ggplot(r0_stats_by_date, aes(date, median_r0, colour = lockdown_period)) +
geom_hline(aes(yintercept = 1), colour = 'firebrick', size = 0.75, linetype = 'dashed') +
# geom_ribbon(aes(ymin = q25, ymax = q75, fill = lockdown_period), alpha = 0.3) +
# facet_wrap(~lockdown_period, ncol = 1) +
theme_bw() +
geom_line(size = 0.75) +
# geom_point(aes(size = pct_of_states)) +
labs(
x = '', y = 'Median Rolling 7-Day R0',
caption = 'Chart: Taylor G. White\nData: covidtracking.com',
title = 'COVID-19 Rolling 7-Day Reproduction Number (R0) by Lockdown Status',
subtitle = sprintf('U.S. states, through %s. Data is lagged by one week for case delay and one week to observe follow-on cases for R0 computation. R0 < 1 means the rate of new cases is decreasing.',
max(all_covid_data_diffs_dates$date) %>% format('%B %d')
) %>% str_wrap(115)
) +
theme(
panel.grid.minor = element_blank(),
legend.text = element_text(size = 12),
title = element_text(size = 14),
plot.subtitle = element_text(size = 11, face = 'italic'),
plot.caption = element_text(size = 10, face = 'italic', hjust = 0),
legend.position = 'right'
) +
scale_size(name = '% of States', range = c(1, 4), labels = percent) +
scale_colour_hue(name = 'Period') +
scale_y_continuous(breaks = seq(0, 15, by = 1))
ggsave('output/rolling_ro_trend_by_lockdown_status.png', height = 8, width = 10, units = 'in', dpi = 800)
latest_state_data = filter(all_covid_data_diffs_dates, location != 'United States', date == max(date)) %>%
arrange(-value_total_cases) %>%
mutate(
location_factor = factor(location, levels = location)
)
all_covid_data_diffs_dates$location_factor = factor(all_covid_data_diffs_dates$location,
levels = latest_state_data$location)
filter(all_covid_data_diffs_dates,
location %in% head(latest_state_data, 50)$location, date >= as.Date('2020-03-11')) %>%
ggplot() +
facet_wrap(~location_factor, scales = 'free_y', ncol = 5) +
geom_area(aes(date, rolling7_tests_with_results/pop_100k), fill = 'black', alpha = .4) +
# geom_area(aes(date, rolling7_percent_positive_new_tests), fill = 'black', alpha = .4) +
geom_line(aes(date, rolling3_new_cases/pop_100k, colour = rolling3_new_cases/rolling7_tests_with_results), size = 0.75) +
# geom_point(aes(date, rolling3_percent_positive_new_tests), colour = 'blue') +
# geom_point(aes(date, rolling3_percent_positive_new_tests, size = new_cases_per_100k), colour = 'red') +
theme_bw() +
theme(strip.background = element_blank(), panel.grid = element_blank()) +
scale_size(range = c(1, 5)) +
scale_x_date(date_breaks = '7 days', date_labels = '%b %d') +
scale_y_continuous(labels = comma) +
labs(
y = '3 Day Average of New Cases Per 100k', x = '',
title = 'Daily Average Testing Per Week Versus Positive Test Results, Per 100k Population'
)
filter(all_covid_data_diffs_dates,
location %in% head(latest_state_data, 50)$location, date >= as.Date('2020-03-11')) %>%
ggplot() +
facet_wrap(~location_factor, scales = 'free_y', ncol = 5) +
geom_area(aes(date, rolling7_tests_with_results/pop_100k), fill = 'black', alpha = .4) +
# geom_area(aes(date, rolling7_percent_positive_new_tests), fill = 'black', alpha = .4) +
geom_line(aes(date, rolling3_new_cases/pop_100k, colour = rolling3_new_cases/rolling7_tests_with_results), size = 0.75) +
scale_color_viridis_c(option = 'C') +
theme_bw() +
theme(strip.background = element_blank(), panel.grid = element_blank()) +
scale_size(range = c(1, 5)) +
scale_x_date(date_breaks = '7 days', date_labels = '%b %d') +
scale_y_continuous(labels = comma) +
labs(
y = '3 Day Average of New Cases Per 100k', x = '',
title = 'Daily Average Testing Per Week Versus Positive Test Results, Per 100k Population'
)
filter(all_covid_data_diffs_dates,
location %in% head(latest_state_data, 50)$location, date >= as.Date('2020-03-11')) %>%
ggplot() +
facet_wrap(~location_factor, scales = 'free_y', ncol = 5) +
geom_area(aes(date, rolling7_tests_with_results/pop_100k), fill = 'black', alpha = .4) +
# geom_area(aes(date, rolling7_percent_positive_new_tests), fill = 'black', alpha = .4) +
geom_line(aes(date, rolling3_new_cases/pop_100k, colour = log(rolling3_new_cases/rolling7_tests_with_results)), size = 0.75) +
scale_color_viridis_c(option = 'C') +
theme_bw() +
theme(strip.background = element_blank(), panel.grid = element_blank()) +
scale_size(range = c(1, 5)) +
scale_x_date(date_breaks = '7 days', date_labels = '%b %d') +
scale_y_continuous(labels = comma) +
labs(
y = '3 Day Average of New Cases Per 100k', x = '',
title = 'Daily Average Testing Per Week Versus Positive Test Results, Per 100k Population'
)
filter(all_covid_data_diffs_dates,
location %in% head(latest_state_data, 50)$location, date >= as.Date('2020-03-11')) %>%
ggplot() +
facet_wrap(~location_factor, scales = 'free_y', ncol = 5) +
geom_area(aes(date, rolling7_tests_with_results/pop_100k), fill = 'black', alpha = .4) +
# geom_area(aes(date, rolling7_percent_positive_new_tests), fill = 'black', alpha = .4) +
geom_line(aes(date, rolling3_new_cases/pop_100k), colour = 'blue', size = 0.75) +
# geom_point(aes(date, rolling3_percent_positive_new_tests), colour = 'blue') +
# geom_point(aes(date, rolling3_percent_positive_new_tests, size = new_cases_per_100k), colour = 'red') +
theme_bw() +
theme(strip.background = element_blank(), panel.grid = element_blank()) +
scale_size(range = c(1, 5)) +
scale_x_date(date_breaks = '7 days', date_labels = '%b %d') +
scale_y_continuous(labels = comma) +
labs(
y = '3 Day Average of New Cases Per 100k', x = '',
title = 'Daily Average Testing Per Week Versus Positive Test Results, Per 100k Population'
)
